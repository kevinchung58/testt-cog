import { ChromaClient, Collection, OpenAIEmbeddingFunction } from 'chromadb'; // ChromaClient from chromadb package
import { CHROMA_URL, OPENAI_API_KEY } from '../config';

let client: ChromaClient | undefined;
let openaiEmbedder: OpenAIEmbeddingFunction | undefined;

function getClient(): ChromaClient {
  if (!client) {
    if (!CHROMA_URL) {
      throw new Error('CHROMA_URL is not set. Vector DB service cannot operate.');
    }
    try {
      client = new ChromaClient({ path: CHROMA_URL });
      console.log('ChromaDB client initialized successfully.');
    } catch (error: any) {
      console.error('Failed to initialize ChromaDB client:', error.message);
      throw new Error('Could not initialize ChromaDB client.');
    }
  }
  return client;
}

// Initialize OpenAIEmbedder if API key is available
if (OPENAI_API_KEY) {
    openaiEmbedder = new OpenAIEmbeddingFunction({ openai_api_key: OPENAI_API_KEY });
} else {
    console.warn('OPENAI_API_KEY not set, ChromaDB will not be able to use OpenAI embeddings by default for query_texts.');
}

export async function getOrCreateCollection(collectionName: string): Promise<Collection> {
  const chromaClient = getClient();
  try {
    // If using OpenAI embeddings generated by our llmService, we don't strictly need to pass an embedder to getOrCreateCollection
    // unless we want Chroma to handle embeddings for queryTexts automatically.
    // For adding pre-computed embeddings, no embeddingFunction is strictly needed at collection creation.
    // However, if we want `collection.query({ queryTexts: [...] })` to work, an embedder is useful.
    const collection = await chromaClient.getOrCreateCollection({
        name: collectionName,
        // embeddingFunction: openaiEmbedder // Optional: if we want queryTexts to be auto-embedded by Chroma
    });
    console.log(`Collection '${collectionName}' ensured.`);
    return collection;
  } catch (error: any) {
    console.error(`Error getting or creating collection '${collectionName}':`, error.message);
    throw error;
  }
}

export async function addOrUpdateChunks(
  collectionName: string,
  ids: string[],
  embeddings: number[][],
  documents: string[],
  metadatas: Record<string, any>[],
): Promise<void> {
  if (ids.length === 0) {
    console.log('No documents to add or update.');
    return;
  }
  try {
    const collection = await getOrCreateCollection(collectionName);
    // Chroma's add function also acts as an upsert if IDs already exist (behavior might vary by version)
    await collection.add({
      ids: ids,
      embeddings: embeddings,
      documents: documents,
      metadatas: metadatas,
    });
    console.log(`Successfully added/updated ${ids.length} documents in collection '${collectionName}'.`);
  } catch (error: any) {
    console.error(`Error adding/updating documents to collection '${collectionName}':`, error.message);
    throw error;
  }
}

export async function searchSimilarChunks(
  collectionName: string,
  queryEmbeddings: number[][], // Expect pre-computed embeddings for querying
  k: number = 5,
): Promise<any[][]> { // Returns an array of arrays of results (one array per query embedding)
  try {
    const collection = await getOrCreateCollection(collectionName);
    if (!queryEmbeddings || queryEmbeddings.length === 0) {
      return [];
    }
    const results = await collection.query({
      queryEmbeddings: queryEmbeddings,
      nResults: k,
      // include: ['metadatas', 'documents', 'distances'] // Specify what to include in results
    });
    // The structure of 'results' can be complex. Let's simplify it to return documents or metadatas.
    // For now, returning the raw 'results.documents' or similar based on what you need.
    // Example: results.documents, results.metadatas, results.ids, results.distances
    // Each of these is an array of arrays if multiple query embeddings were provided.
    console.log(`Search in '${collectionName}' found results for ${queryEmbeddings.length} queries.`);
    return results.documents ?? []; // Returning document texts by default
  } catch (error: any) {
    console.error(`Error searching in collection '${collectionName}':`, error.message);
    throw error;
  }
}

// Example of querying with text (if collection was created with an embedder)
export async function searchSimilarChunksWithText(
 collectionName: string,
 queryTexts: string[],
 k: number = 5,
): Promise<any[][]> {
 if (!openaiEmbedder) {
     console.warn("OpenAIEmbedder not available. Cannot search with text without an API key.");
     return queryTexts.map(() => []);
 }
 try {
     const collection = await getClient().getCollection({name: collectionName, embeddingFunction: openaiEmbedder});
     const results = await collection.query({
         queryTexts: queryTexts,
         nResults: k,
     });
     console.log(`Search (with text) in '${collectionName}' found results for ${queryTexts.length} queries.`);
     return results.documents ?? [];
 } catch (error: any) {
     console.error(`Error searching with text in collection '${collectionName}':`, error.message);
     throw error;
 }
}

// Exported for testing purposes only
export function _resetChromaClientForTesting() {
  client = undefined;
  // Re-initialize openaiEmbedder based on the current state of OPENAI_API_KEY (which might be mocked in tests)
  if (OPENAI_API_KEY) {
      openaiEmbedder = new OpenAIEmbeddingFunction({ openai_api_key: OPENAI_API_KEY });
  } else {
      openaiEmbedder = undefined;
  }
}
